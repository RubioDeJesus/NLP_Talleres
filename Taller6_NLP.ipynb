{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de Lenguage Natural\n",
    "\n",
    "#### Taller #6: Word2Vec\n",
    "\n",
    "#### Uso de Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir el archivo glove.840B.300d.txt formato  word2vec  ejecuto desde anaconda promp\n",
    "# python -m gensim.scripts.glove2word2vec --input data/glove.840B.300d.txt --output data/word2vec_from_glove_300.vec\n",
    "# Salida\n",
    "# glove2word2vec - INFO - converting 2196017 vectors from data/glove.840B.300d.txt to data/word2vec_from_glove_300.vec\n",
    "# glove2word2vec - INFO - Converted model with 2196017 vectors and 300 dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar una cantidad fija de vectores \n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "wordvectors_file_vec = 'data/word2vec_from_glove_300.vec'\n",
    "cantidad = 500000\n",
    "wordvectors = KeyedVectors.load_word2vec_format(wordvectors_file_vec, limit=cantidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('automobile', 0.7418984174728394),\n",
       " ('Auto', 0.7060839533805847),\n",
       " ('car', 0.6832497119903564),\n",
       " ('autos', 0.6676468849182129),\n",
       " ('automotive', 0.6382536292076111),\n",
       " ('insurance', 0.6227496266365051),\n",
       " ('dealership', 0.6088051795959473),\n",
       " ('cars', 0.5895304083824158),\n",
       " ('dealerships', 0.5726405382156372),\n",
       " ('vehicle', 0.5697208046913147)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvectors.most_similar(\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rey', 0.8072925806045532),\n",
       " ('prado', 0.7801428437232971),\n",
       " ('lobo', 0.7780134677886963),\n",
       " ('Reina', 0.7762184143066406),\n",
       " ('leon', 0.7705879807472229),\n",
       " ('cordoba', 0.7669919729232788),\n",
       " ('torres', 0.7665282487869263),\n",
       " ('pepe', 0.7652010321617126),\n",
       " ('sergio', 0.7599021196365356),\n",
       " ('casillas', 0.7586633563041687)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Con distinicion de genero,  se presenta novedad con las mayusculas\n",
    "wordvectors.most_similar_cosmul(positive=['reina','hombre'],negative=['mujer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('actriz', 0.9428027868270874),\n",
       " ('cantante', 0.9029945135116577),\n",
       " ('regista', 0.8718931078910828),\n",
       " ('famosa', 0.8681918978691101),\n",
       " ('escena', 0.8633278608322144),\n",
       " ('presentación', 0.8628295063972473),\n",
       " ('quella', 0.8620656728744507),\n",
       " ('diventa', 0.8614970445632935),\n",
       " ('questa', 0.861271858215332),\n",
       " ('interpreta', 0.8585531711578369)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvectors.most_similar_cosmul(positive=['protagonista','mujer'],negative=['hombre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rojo'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #términos excluídos\n",
    "wordvectors.doesnt_match(['actriz','escena','rojo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rey'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conjugaciones\n",
    "wordvectors.doesnt_match(['Auto','autos','rey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('motors', 0.8048527240753174),\n",
       " ('Motor', 0.628271758556366),\n",
       " ('engine', 0.6199028491973877),\n",
       " ('vehicle', 0.5907812714576721),\n",
       " ('electric', 0.5799087285995483),\n",
       " ('automobile', 0.5732433199882507),\n",
       " ('alternator', 0.5670548677444458),\n",
       " ('car', 0.5655214190483093),\n",
       " ('wheel', 0.5636961460113525),\n",
       " ('torque', 0.5504360198974609)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10\n",
    "wordvectors.most_similar(\"motor\",topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"d'avion\", 0.698983907699585),\n",
       " ('Billets', 0.6322997808456421),\n",
       " ('Avion', 0.6172570586204529),\n",
       " ('voiture', 0.6092437505722046),\n",
       " ('billets', 0.5345495939254761),\n",
       " ('Bucarest', 0.5314152240753174),\n",
       " ('londres', 0.5310180187225342),\n",
       " ('voitures', 0.5279659032821655),\n",
       " ('aeroport', 0.5091251134872437),\n",
       " ('aéroport', 0.5026881098747253)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvectors.most_similar(\"avion\",topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Su modelo da buenos resultados? ¿Por qué sí o por qué no?\n",
    "No porque al limitar el tamaño tambien reduce las posbles palabras, por ejemplo con 100.000 no aparecia Reina, con 500.000 si pero no es garantia.\n",
    "Las tildes interfieren considerablemente\n",
    "\n",
    "## ¿Qué problemas encontró al realizar este taller?\n",
    " Los tamaños de los embeddings son muy grandes y no son faciles de trabajar, es dificil buscar un buen insumo pequeño, porque si es pequeño no es muy completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
